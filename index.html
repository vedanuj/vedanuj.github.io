<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/logo.jpg">
  <title>Vedanuj Goswami</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Vedanuj Goswami</name>
              </p>
              <p>I am a research engineer at <a href="https://ai.facebook.com/">Meta Research (FAIR)</a> focusing on machine translation and multimodal understanding. Previously I worked on computer vision for AR/VR at Meta Reality Labs. I did my Masters in machine learning from <a href="https://www.ic.gatech.edu/">Georgia Tech</a>. Before that, I received a Bachelor's degree in computer science from <a href="http://cs.nits.ac.in/">NITS, India</a> and worked briefly at Samsung Camera R&D.
              </p>
              <p align=center>
                <a href="mailto:vedanujg@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://github.com/vedanuj">Github</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=bh08FeIAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="http://www.linkedin.com/in/vedanuj/"> LinkedIn </a> &nbsp/&nbsp
                <a href="https://twitter.com/vedanujg"> Twitter </a>
              </p>
            </td>
            <td width="33%">
              <img src="images/image.jpg">
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <div>
            <td width="100%" valign="middle">
              <heading>Research</heading>
              <p>
                My research focuses on machine learning, computer vision and natural language processing.  In particular, I am interested in large scale self supervised training, multitask learning for multimodal understanding and machine translation.
              </p>
              <!-- Representative papers are <span class="highlight">highlighted</span>. -->
            </td>
          </div>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tr>
            <td>
                <a href="https://arxiv.org/pdf/2207.04672.pdf">
                  <papertitle>No Language Left Behind: Scaling Human-Centered Machine Translation</papertitle></a><br><br>
                  NLLB Team*, Marta R. Costa-jussa*, James Cross*, Onur Celebi*, Maha Elbayad*, Kenneth Heafield*, Kevin Heffernan*, Elahe Kalbassi*, Janice Lam*, Daniel Licht*, Jean Maillard*, Anna Sun*, Skyler Wang*, Guillaume Wenzek*, Al Youngblood*, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews&dagger;, Necip Fazil Ayan&dagger;, Shruti Bhosale&dagger;, Sergey Edunov&dagger;, Angela Fan&dagger;, Cynthia Gao&dagger;, <strong>Vedanuj Goswami&dagger;</strong>, Francisco Guzman&dagger;, Philipp Koehn&dagger;, Alexandre Mourachko&dagger;, Christophe Ropers&dagger;, Safiyyah Saleem&dagger;, Holger Schwenk&dagger;, Jeff Wang&dagger;
                  <br> &dagger; Research and engineering leadership, equal contribution <br><br>
                <a href="https://arxiv.org/abs/2207.04672">arxiv</a> / <a href="https://ai.facebook.com/research/no-language-left-behind/">website</a> / <a href="https://github.com/facebookresearch/fairseq/tree/nllb">code</a> / <a href="https://nllb.metademolab.com/">demo</a>
              <p></p>
              <p>A massively multilingual model that can translate between any pair among 200+ languages.</p>
            </td>
            </tr>

          <tr>
            <td>
                <a href="https://arxiv.org/pdf/2112.04482.pdf">
                  <papertitle>FLAVA: A Foundational Language And Vision Alignment Model</papertitle></a><br>
                  Amanpreet Singh*, Ronghang Hu*, <strong>Vedanuj Goswami*</strong>, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, Douwe Kiela
                <br> * equal contribution <br>
                <em>CVPR</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2112.04482">arxiv</a> / <a href="https://flava-model.github.io/">website</a> / <a href="https://github.com/facebookresearch/multimodal/tree/main/examples/flava">code</a>
              <p></p>
              <p>A foundaltional model for vision and language alignment, that can perform vision, language, and cross- and multi-modal vision and language tasks.</p>
            </td>
            </tr>

          <tr>
            <td>
                <a href="https://openreview.net/forum?id=gwnoVHIES05">
                  <papertitle>Creative Sketch Generation</papertitle></a><br>
                  Songwei Ge, <strong>Vedanuj Goswami</strong>, Larry Zitnick, Devi Parikh
                <br>
                <em>ICLR</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2011.10039">arxiv</a> / <a href="">bibtex</a> / <a href="">slides</a>
              <p></p>
              <p>Two new datasets for creative skecthes and a novel model(DoodlerGAN) to generate unseen compositions of novel part appearances.</p>
            </td>
            </tr>

          <tr>
            <td>
                <a href="https://openreview.net/forum?id=8e6BrwU6AjQ">
                  <papertitle>MoVie: Revisiting Modulated Convolutions for Visual Counting and Beyond</papertitle></a><br>
                  Duy-Kien Nguyen, <strong>Vedanuj Goswami</strong>, Xinlei Chen
                <br>
                <em>ICLR</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2004.11883">arxiv</a> / <a href="">bibtex</a> / <a href="https://www.iclr.cc/media/iclr-2021/Slides/3071.pdf">slides</a>
              <p></p>
              <p>Modulated convolutional bottleneck architecture for improving visual counting, which achieves SOTA in VQA and winner of 2020 VQA Challenge at CVPR.</p>
            </td>
            </tr>

          <tr>
            <td>
                <a href="https://proceedings.neurips.cc/paper/2021/file/aa97d584861474f4097cf13ccb5325da-Paper.pdf">
                  <papertitle>Human-adversarial Visual Question Answering</papertitle></a><br>
                  Sasha Sheng, Amanpreet Singh, <strong>Vedanuj Goswami</strong>, Jose Magana, Tristan Thrush, Wojciech Galuba, Devi Parikh, Douwe Kiela
                <br>
                <em>NeurIPS</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2106.02280">arxiv</a> / <a href="https://adversarialvqa.org/">website</a> / <a href="https://dblp.org/rec/bib/journals/corr/abs-1907-08340">bibtex</a> / <a href="https://nips.cc/media/neurips-2021/Slides/26315.pdf">slides</a>
              <p></p>
              <p>Adversarial dataset and benchmark that is collected with Human-and-Model-in-the-loop for evaluating the robustness of state-of-the-art VQA systems.</p>
            </td>
            </tr>

          <tr>
            <td>
                <a href="https://proceedings.neurips.cc/paper/2020/file/1b84c4cee2b8b3d823b30e2d604b1878-Paper.pdf">
                  <papertitle>The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes</papertitle></a><br>
                  Douwe Kiela, Hamed Firooz, Aravind Mohan, <strong>Vedanuj Goswami</strong>, Amanpreet Singh, Pratik Ringshia, Davide Testuggine
                <br>
                <em>NeurIPS</em>, 2020
                <br>
                <a href="https://arxiv.org/abs/2005.04790">arxiv</a> / <a href="https://ai.facebook.com/blog/hateful-memes-challenge-and-data-set/">blog</a> / <a href="https://dblp.org/rec/bib/journals/corr/abs-1907-08340">bibtex</a> / <a href="https://github.com/facebookresearch/mmf/tree/main/projects/hateful_memes">code</a>
              <p></p>
              <p>New benchmark for multimodal classification, focusing on detecting hate speech in multimodal memes.</p>
            </td>
            </tr>

          <tr>
            <td>
                <a href="https://arxiv.org/pdf/1907.08340.pdf">
                  <papertitle>Only Time Can Tell: Discovering Temporal Data for Temporal Modeling</papertitle></a><br>
                  Laura Sevilla-Lara, Shengxin Zha, Zhicheng Yan, <strong>Vedanuj Goswami</strong>, Matt Feiszli, Lorenzo Torresani
                <br>
                <em>WACV</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/1907.08340">arxiv</a> / <a href="https://ai.facebook.com/blog/introducing-the-temporal-data-set-a-benchmark-for-recognizing-actions-in-videos/">blog</a> / <a href="https://dblp.org/rec/bib/journals/corr/abs-1907-08340">bibtex</a>
              <p></p>
              <p>A methodology to discover the relevance of temporal information in action classes and use it to identify categories that contain more temporal information <em>(temporal classes)</em>.</p>
            </td>
            </tr>
          
          <tr>
            <td>
                <a href="https://arxiv.org/pdf/1912.02315.pdf">
                  <papertitle>12-in-1: Multi-Task Vision and Language Representation Learning</papertitle></a><br>
                Jiasen Lu*, <strong>Vedanuj Goswami*</strong>, Marcus Rohrbach, Devi Parikh, Stefan Lee
                <br> * equal contribution <br>
                <em>CVPR</em>, 2020
                <br>
                <a href="https://arxiv.org/abs/1912.02315">arxiv</a> / <a href="https://dblp.org/rec/bibtex/journals/corr/abs-1912-02315">bibtex</a>
              <p></p>
              <p>An approach for effective multi-task learning. Trained a single model on 12 popular vision-and-language tasks improving upon individual task-specific models.
                datasets..</p>
            </td>
            </tr>
          
            <tr>
              <td>
                  <a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/CVFAD/Pumarola_Unsupervised_Image-to-Video_Clothing_Transfer_ICCVW_2019_paper.pdf">
                    <papertitle>Unsupervised Image-to-Video Clothing Transfer</papertitle></a><br>
                    Albert Pumarola, <strong>Vedanuj Goswami</strong>, Francisco Vicente, <a href="https://research.fb.com/people/de-fernando-de-la-tor/">Fernando De la Torre</a>, Francesc Moreno-Noguer
                    <br>
                    <em>ICCV Workshop</em>, 2019
                    <br>
                  <a href="http://openaccess.thecvf.com/content_ICCVW_2019/html/CVFAD/Pumarola_Unsupervised_Image-to-Video_Clothing_Transfer_ICCVW_2019_paper.html">website</a>
                <p></p>
                <p>Unsupervised photo-realistic transfer of clothing of a person in a reference image into another person in an unconstrained image or video.</p>
              </td>
              </tr>

          <tr>
          <td>
              <a href="https://link.springer.com/chapter/10.1007/978-3-319-47096-2_23">
                <papertitle>Knowledge Extraction and Annotation for Cross-Domain Textual Case-Based Reasoning in Biologically Inspired Design</papertitle></a><br>
              <a href="http://dilab.gatech.edu/spencer-rugaber/">Spencer Rugaber</a>, Shruti Bhati, <strong>Vedanuj Goswami</strong>, Evangelia Spiliopoulou, Sasha Azad, Sridevi Koushik, Rishikesh Kulkarni, Mithun Kumble, Sriya Sarathy,
              <a href="http://dilab.gatech.edu/ashok-k-goel/">Ashok Goel</a>
              <br>
              <em>ICCBR</em>, 2016
              <br>
              <a href="http://dilab.gatech.edu/test/wp-content/uploads/2016/11/ICCBR2016.pdf">pdf</a> /
              <a href="http://dilab.gatech.edu/publications/knowledge-extraction-and-annotation-for-cross-domain-textual-case-based-reasoning-in-biologically-inspired-design/">blog</a> /
              <a href="http://dilab.gatech.edu/ibid-poster-presented-in-iccbr-2016/">poster</a> /
              <a href="https://dblp.org/rec/bibtex/conf/iccbr/RugaberBGSAKKKS16">bibtex</a>
            <p></p>
            <p>NLP framework for extracting partial SBF <em>(Structure, Behavior, Function)</em> models of biological systems from natural language documents for potential use in biologically inspired design.</p>
          </td>
          </tr>

          <tr>
            <td>
                <a href="https://link.springer.com/chapter/10.1007/978-3-319-14803-8_19">
                  <papertitle>Grammarless Language Generation Algorithm Based on Idiotypic Artificial Immune Networks</papertitle></a><br>
                <strong>Vedanuj Goswami</strong>, Samir Borgohain
                <br>
                <em>ACALCI</em>, 2015
                <br>
                <a href="https://github.com/vedanuj/language-learning-immune-networks">code</a> /
                <a href="data/acalci.bib">bibtex</a>
              <p></p>
              <p>Algorithm to differentiate between correct and wrong grammatical sentence constructs using artificial immune networks.</p>
            </td>
            </tr>
        </table>
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Course Projects</heading>
            </td>
          </tr>
        </table> -->
        <!-- <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <tr onmouseout="ig_stop()" onmouseover="ig_start()">
              <td width="25%">
                <div class="one">
                  <div class="two" id='ig_image'><img src='images/ig_2.jpeg' width="160" height="160"></div>
                  <img src='images/ig_1.jpeg' width="160" height="160">
                </div>
                <script type="text/javascript">
                  function ig_start() {
                    document.getElementById('ig_image').style.opacity = "1";
                  }
  
                  function ig_stop() {
                    document.getElementById('ig_image').style.opacity = "0";
                  }
                  ig_stop()
                </script>
              </td>
            <td width="75%" valign="top">
              <p>
                <a href="data/ig.pdf">
                  <papertitle>Analyzing and Recommending Photo Filters from Image Category and User Engagement Metadata</papertitle>
                </a>
                <br>
                <strong>Vedanuj Goswami</strong>, Anil Muppalla, Abhishek Sen, Siddharth Shah, Duen Horng Chau, 2016
                <br>
                <a href="data/ig_poster.pdf">poster</a> /
                <a href="https://github.com/abhishekpsen/InstagramVisualization">code</a>
                <p>
                  <br> Recommendation of photo filters using a k-nearest neighbor algorithm, convolutional neural network based on user engagement metrics and scores in Instagram images.
                </p>
              </p>
            </td>
          </tr>
          <tr>
            <tr onmouseout="bdh_stop()" onmouseover="bdh_start()">
              <td width="25%">
                <div class="one">
                  <div class="two" id='bdh_image'><img src='images/bdh_1.png' width="160" height="160"></div>
                  <img src='images/bdh_0.png' width="160" height="160">
                </div>
                <script type="text/javascript">
                  function bdh_start() {
                    document.getElementById('bdh_image').style.opacity = "1";
                  }
  
                  function bdh_stop() {
                    document.getElementById('bdh_image').style.opacity = "0";
                  }
                  bdh_stop()
                </script>
              </td>
            <td width="75%" valign="top">
              <p>
                <a href="data/ig.pdf">
                  <papertitle>Topic Modelling on Patient Notes for ICU Mortality Prediction</papertitle>
                </a>
                <br>
                <strong>Vedanuj Goswami</strong>, 2016
                <br>
                <a href="https://www.youtube.com/watch?v=KcCMpd6SGkw">video</a> /
                <a href="https://github.com/vedanuj/mortality-prediction-lda">code</a>
                <p>
                  <br>  Used Latent Dirichlet Analysis on patient notes which improved true positive over false positive rate for mortality prediction in ICUs.
                </p>
              </p>
            </td>
          </tr>
          <tr>
            <tr onmouseout="sdn_stop()" onmouseover="sdn_start()">
              <td width="25%">
                <div class="one">
                  <div class="two" id='sdn_image'><img src='images/sdn1.png' width="160" height="160"></div>
                  <img src='images/sdn0.png' width="160" height="160">
                </div>
                <script type="text/javascript">
                  function sdn_start() {
                    document.getElementById('sdn_image').style.opacity = "1";
                  }
  
                  function sdn_stop() {
                    document.getElementById('sdn_image').style.opacity = "0";
                  }
                  sdn_stop()
                </script>
              </td>
            <td width="75%" valign="top">
              <p>
                <a href="data/sdn.pdf">
                  <papertitle>Simple ElastiCon : A Distributed SDN Controller</papertitle>
                </a>
                <br>
                <strong>Vedanuj Goswami</strong>, Aditya V Kamath, Abhishek Sen, Brenden Raulerson, Sai Teja Duthuluri, 2016
                <p>
                  <br> A distributed SDN controller which dynamically changes switch allocation among controllers depending on the load being experienced by the controllers.
                </p>
              </p>
            </td>
          </tr>
      </table> -->


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tbody><tr>
        <!--<td width="25%"><img src="./_files/teach_crop.jpg" alt="teach" width="160" height="160"></td>-->
        <td width="75%" valign="center">
          <p>
        <a href="https://www.udacity.com/course/knowledge-based-ai-cognitive-systems--ud409">
            <papertitle>GaTech CS7637: Knowledge Based Artificial Intelligence</papertitle>
        </a>, Fall 2015, 2016, Spring 2016
        - Teaching Assistant (TA) <br>

        </p>
        </td>
      </tr>
      </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  Template from <a href="https://jonbarron.info/"> here</a>
              </p>
            </td>
          </tr>
        </table>
        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr>
  </table>
</body>

</html>
